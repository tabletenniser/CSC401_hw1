Method performed in subtask 3.1 definitely has lots of room for improvement. For example, the decision tree algorithm obtains 80.05% classification rate on the training set but only 51.81% on the unseen test dataset. This is a strong indication that our classifier overfits the training data and cross-validation should be used to tune the model hyper-parameters to prevent such overfit.

The 10-fold cross validation accuracy for the Naive Bayes classifier is summarized below:
[0.625, 0.597, 0.578, 0.615, 0.625, 0.596, 0.623, 0.643, 0.575, 0.595]
Average: 0.6072

The 10-fold cross validation precision for the Naive Bayes classifier is summarized below:
Class a = 0:
[0.668, 0.628, 0.610, 0.655, 0.646, 0.641, 0.656, 0.681, 0.601, 0.623]
Average: 0.6409
Class b = 4:
[0.600, 0.579, 0.561, 0.592, 0.609, 0.573, 0.601, 0.618, 0.560, 0.577]
Average: 0.5870

The 10-fold cross validation recall for the Naive Bayes classifier is summarized below:
Class a = 0:
[0.498, 0.478, 0.434, 0.487, 0.551, 0.438, 0.516, 0.536, 0.449, 0.478]
Average: 0.xxxx
Class b = 4:
[0.753, 0.716, 0.722, 0.743, 0.698, 0.755, 0.729, 0.749, 0.702, 0.711]
Average: 0.xxxx



The original confusion matrix from each of the cross validation is attached below:

   a   b   <-- classified as
 274 276 |   a = 0
 136 414 |   b = 4

    a   b   <-- classified as
 263 287 |   a = 0
 156 394 |   b = 4

    a   b   <-- classified as
 239 311 |   a = 0
 153 397 |   b = 4

   a   b   <-- classified as
 268 282 |   a = 0
 141 409 |   b = 4

    a   b   <-- classified as
 303 247 |   a = 0
 166 384 |   b = 4


    a   b   <-- classified as
 241 309 |   a = 0
 135 415 |   b = 4

    a   b   <-- classified as
 284 266 |   a = 0
 149 401 |   b = 4

    a   b   <-- classified as
 295 255 |   a = 0
 138 412 |   b = 4

    a   b   <-- classified as
 247 303 |   a = 0
 164 386 |   b = 4

   a   b   <-- classified as
 263 287 |   a = 0
 159 391 |   b = 4